{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d647a77-9f10-42aa-b4ce-69bf49a91328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 1: Project Predictive Model\n",
    "# Objective:\n",
    "# Develop a machine learning model that predicts the likelihood of a customer making a purchase using the provided customer, product, and transaction datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd82c3e-4849-48d8-b07f-9c00e4da42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0b1bed5-14dd-44c0-bd45-afef1a89bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Explore the Datasets\n",
    "# Before we can build any predictive model, we must first understand the structure and contents of the data. This is done by loading the datasets and conducting an initial exploratory data analysis (EDA).\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/customernew.csv')\n",
    "df2 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/productnew.csv')\n",
    "df3 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/transactionsnew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b933801-134f-4323-bcf4-59f831a4e8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Company_ID        Company_Name  Company_Profit    City\n",
      "0           1    Tech Enterprises         80701.0   Pasig\n",
      "1           2     Global Partners         80511.0  Taguig\n",
      "2           3  Quantum Associates        110664.0   Pasig\n",
      "3           4       Prime Network             NaN  Taguig\n",
      "4           5      Elite Ventures         69427.0  Makati\n",
      "   Product_ID            Product_Name Product_Price\n",
      "0         1.0      FinPredictor Suite       140,000\n",
      "1         2.0  MarketMinder Analytics       168,000\n",
      "2         3.0    TrendWise Forecaster       100,800\n",
      "3         4.0  CustomerScope Insights       123,200\n",
      "4         5.0     SalesSync Optimizer        84,000\n",
      "   Transaction_ID  Company_ID  Product_ID Quantity Transaction_Date  \\\n",
      "0             1.0        88.0         6.0        6       26-03-2024   \n",
      "1             2.0        29.0        19.0       15       09-07-2024   \n",
      "2             NaN        28.0        18.0        7       13-04-2024   \n",
      "3             4.0        85.0        12.0  #DIV/0!       06-09-2023   \n",
      "4             5.0        47.0         3.0        7       06-07-2021   \n",
      "\n",
      "   Product_Price  Total_Cost  \n",
      "0      194379.15   1075200.0  \n",
      "1       97930.99   1428000.0  \n",
      "2      126095.55    940800.0  \n",
      "3            NaN   1008000.0  \n",
      "4       99575.61    705600.0  \n",
      "Company_ID         0\n",
      "Company_Name       0\n",
      "Company_Profit    12\n",
      "City               0\n",
      "dtype: int64\n",
      "Product_ID       2\n",
      "Product_Name     0\n",
      "Product_Price    0\n",
      "dtype: int64\n",
      "Transaction_ID      1000\n",
      "Company_ID          1000\n",
      "Product_ID          1000\n",
      "Quantity               0\n",
      "Transaction_Date       0\n",
      "Product_Price       1000\n",
      "Total_Cost          1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initial Exploration\n",
    "# We'll inspect the first few rows and check for missing values to understand the dataset's completeness and structure.\n",
    "\n",
    "# Preview datasets\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "print(df3.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "539ff64b-b4e3-47de-9056-05e42c793241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Cleaning & Preprocessing\n",
    "# Data cleaning ensures the data is in a suitable format for analysis and modeling. This involves handling missing values, fixing data types, and standardizing formats.\n",
    "\n",
    "# Handling Missing Values\n",
    "# Missing values can lead to incorrect model predictions or errors during model training. Depending on the nature and significance of the missing data, we can either fill them with statistical values (mean, median) or remove the affected rows.\n",
    "\n",
    "# For numerical columns like Company_Profit:\n",
    "# Replace missing values with the median profit. Median is preferred over mean in case of outliers.\n",
    "df1['Company_Profit'] = df1['Company_Profit'].fillna(df1['Company_Profit'].median())\n",
    "\n",
    "# For transactions missing Transaction_ID:\n",
    "# Transactions without an ID are incomplete and likely erroneous, so we drop them.\n",
    "df3.dropna(subset=['Transaction_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a587143-ba76-4409-b5d7-bca9e4a46732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Data Types\n",
    "# Ensuring data types are consistent is crucial for accurate calculations and modeling. For example, Transaction_Date should be in datetime format, and product prices should be numerical.\n",
    "\n",
    "# Convert Transaction_Date to datetime format:\n",
    "# This will allow us to extract time-based features like purchase frequency over months.\n",
    "df3['Transaction_Date'] = pd.to_datetime(df3['Transaction_Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Convert Product_Price to float:\n",
    "# Remove commas from price strings and convert them to numeric values.\n",
    "df2['Product_Price'] = df2['Product_Price'].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77c0a563-8f21-449f-bbcd-ae2157112986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing Formats Across Datasets\n",
    "# Consistent column names and formats are essential when merging datasets or conducting analysis.\n",
    "\n",
    "# Standardize the Company_ID field across datasets:\n",
    "# This ensures we can merge datasets without errors.\n",
    "df1.rename(columns={'Company_ID': 'CompanyID'}, inplace=True)\n",
    "df3.rename(columns={'Company_ID': 'CompanyID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d36f1f57-ede4-405d-90bc-ad36283859c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Feature engineering is the process of creating new features from the existing data to improve the performance of machine learning models.\n",
    "\n",
    "# Customer Purchase History Features\n",
    "# Understanding a customerâ€™s purchase behavior is key to predicting future purchases. We derive features like total spending, average spending, and the number of transactions per customer..\n",
    "\n",
    "# Total Spending Per Company:\n",
    "# This helps identify big spenders who might be more likely to purchase again.\n",
    "customer_spending = df3.groupby('CompanyID')['Total_Cost'].sum().reset_index()\n",
    "customer_spending.rename(columns={'Total_Cost': 'Total_Spending'}, inplace=True)\n",
    "\n",
    "# Average Spending Per Transaction:\n",
    "# Companies with high average spending per transaction may have higher purchasing power.\n",
    "avg_spending = df3.groupby('CompanyID')['Total_Cost'].mean().reset_index()\n",
    "avg_spending.rename(columns={'Total_Cost': 'Avg_Spending'}, inplace=True)\n",
    "\n",
    "# Number of Transactions Per Company:\n",
    "# More frequent transactions may indicate a loyal customer.\n",
    "transaction_count = df3.groupby('CompanyID')['Transaction_ID'].count().reset_index()\n",
    "transaction_count.rename(columns={'Transaction_ID': 'Transaction_Count'}, inplace=True)\n",
    "\n",
    "# Merge All Features Into Customer Dataset:\n",
    "df1 = df1.merge(customer_spending, on='CompanyID', how='left')\n",
    "df1 = df1.merge(transaction_count, on='CompanyID', how='left')\n",
    "df1 = df1.merge(avg_spending, on='CompanyID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ee3af89-c329-4f01-afd4-a8fdf19dce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Based Features\n",
    "# Time-related behaviors, like purchasing trends over certain months, can indicate future buying intentions.\n",
    "\n",
    "# Extract Month and Year from Transaction_Date:\n",
    "df3['Transaction_Year'] = df3['Transaction_Date'].dt.year\n",
    "df3['Transaction_Month'] = df3['Transaction_Date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c2ff02f-ca9c-4ebd-91ba-0b78f55bbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Building the Predictive Model\n",
    "# Now that the data is prepared, we can build a machine learning model to predict customer purchases.\n",
    "\n",
    "# Define the Target Variable\n",
    "# To predict whether a customer will make a purchase, we need to create a binary target variable.\n",
    "\n",
    "# Create Has_Purchased:\n",
    "# If a customer has made any transactions, label them as 1 (purchased); otherwise, 0 (not purchased).\n",
    "df1['Has_Purchased'] = df1['Transaction_Count'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28956f49-87f1-4204-803e-f392b965c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features and Prepare Data for Modeling\n",
    "# Select features that are relevant for predicting purchase behavior.\n",
    "\n",
    "# Define Feature Set and Target Variable:\n",
    "features = ['Company_Profit', 'Total_Spending', 'Avg_Spending', 'Transaction_Count']\n",
    "target = 'Has_Purchased'\n",
    "\n",
    "X = df1[features].fillna(0)  # Replace NaN with 0\n",
    "y = df1[target]\n",
    "\n",
    "# Split Data into Training and Testing Sets:\n",
    "# Weâ€™ll use 80% of the data for training and 20% for testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7ad02ad-bf40-4e27-838f-29af0eb005c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "# Weâ€™ll use the Random Forest Classifier, a robust algorithm for classification problems.\n",
    "\n",
    "# Train Random Forest Model:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate Model Accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "317b57f7-f25a-4c0e-be7f-58ceb811c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model Evaluation\n",
    "# Evaluating the model helps us understand its performance and areas for improvement.\n",
    "\n",
    "# Generate Confusion Matrix and Classification Report:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix: Shows the true positives, true negatives, false positives, and false negatives.\n",
    "# Precision, Recall, F1-Score: Provides deeper insight into model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ec96bd-f983-465c-91d5-1cbf570c9141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       0.50      0.50      0.50        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#  Ensure Both Classes Are Represented in Test Set\n",
    "# Ensure the data splitting process includes samples from both classes (0 and 1) in the test set using stratification.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure stratified split to maintain class distribution in both train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Add labels Parameter in the Confusion Matrix\n",
    "# Specify the class labels in the confusion matrix.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Explicitly define all possible class labels\n",
    "labels = [0, 1]  # Assuming 0 = No Purchase, 1 = Purchase\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred, labels=labels))\n",
    "print(classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cd25b13-f354-4bb6-8cbc-45f3e9f9437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has_Purchased\n",
      "1    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0f15a5d-d2da-4c84-9d45-4e71abda2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       0.50      0.50      0.50        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Load and Explore the Datasets\n",
    "df1 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/customernew.csv', encoding='ISO-8859-1')\n",
    "df2 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/productnew.csv', encoding='ISO-8859-1')\n",
    "df3 = pd.read_csv('/Users/atrabaja/Documents/FinMark_MachineLearning/transactionsnew.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Data Cleaning & Preprocessing\n",
    "\n",
    "# Handle missing values in Company_Profit\n",
    "df1['Company_Profit'] = df1['Company_Profit'].fillna(df1['Company_Profit'].median())\n",
    "\n",
    "# Remove rows with missing Product_ID\n",
    "df2.dropna(subset=['Product_ID'], inplace=True)\n",
    "\n",
    "# Convert Product_Price to numeric\n",
    "df2['Product_Price'] = df2['Product_Price'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Clean Quantity column in transactions\n",
    "df3['Quantity'] = pd.to_numeric(df3['Quantity'], errors='coerce')\n",
    "df3.dropna(subset=['Quantity'], inplace=True)\n",
    "\n",
    "# Convert Transaction_Date to datetime format\n",
    "df3['Transaction_Date'] = pd.to_datetime(df3['Transaction_Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Standardize Company_ID naming across datasets\n",
    "df1.rename(columns={'Company_ID': 'CompanyID'}, inplace=True)\n",
    "df3.rename(columns={'Company_ID': 'CompanyID'}, inplace=True)\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "\n",
    "# Total spending per company\n",
    "customer_spending = df3.groupby('CompanyID')['Total_Cost'].sum().reset_index()\n",
    "customer_spending.rename(columns={'Total_Cost': 'Total_Spending'}, inplace=True)\n",
    "\n",
    "# Average spending per transaction\n",
    "avg_spending = df3.groupby('CompanyID')['Total_Cost'].mean().reset_index()\n",
    "avg_spending.rename(columns={'Total_Cost': 'Avg_Spending'}, inplace=True)\n",
    "\n",
    "# Number of transactions per company\n",
    "transaction_count = df3.groupby('CompanyID')['Transaction_ID'].count().reset_index()\n",
    "transaction_count.rename(columns={'Transaction_ID': 'Transaction_Count'}, inplace=True)\n",
    "\n",
    "# Merge features with customer data\n",
    "df1 = df1.merge(customer_spending, on='CompanyID', how='left')\n",
    "df1 = df1.merge(transaction_count, on='CompanyID', how='left')\n",
    "df1 = df1.merge(avg_spending, on='CompanyID', how='left')\n",
    "\n",
    "# Create target variable Has_Purchased\n",
    "df1['Has_Purchased'] = df1['Transaction_Count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Step 4: Building the Predictive Model\n",
    "\n",
    "# Select features and target\n",
    "features = ['Company_Profit', 'Total_Spending', 'Avg_Spending', 'Transaction_Count']\n",
    "target = 'Has_Purchased'\n",
    "\n",
    "X = df1[features].fillna(0)\n",
    "y = df1[target]\n",
    "\n",
    "# Split data with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "\n",
    "# Evaluate using confusion matrix and classification report\n",
    "labels = [0, 1]  # Ensure both classes are represented\n",
    "print(confusion_matrix(y_test, y_pred, labels=labels))\n",
    "print(classification_report(y_test, y_pred, labels=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f542d-5bed-4e57-9024-31af55ce8e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
